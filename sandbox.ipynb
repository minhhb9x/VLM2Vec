{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e01b337b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/workspace/VLM2Vec/src/model/baseline_backbone/internvideo2/modeling_internvideo2.py:539: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast(enabled=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DropoutAddRMSNorm of flash_attn is not installed!!!\n"
     ]
    }
   ],
   "source": [
    "from src.arguments import ModelArguments, DataArguments\n",
    "from src.model.model import MMEBModel\n",
    "from src.model.processor import load_processor, LLAVA_QWEN2, VLM_IMAGE_TOKENS, LlavaQwen2_process_fn \n",
    "from src.utils.basic_utils import batch_to_device\n",
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0835c9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = ModelArguments(\n",
    "    model_name='apple/FastVLM-0.5B',\n",
    "    pooling='last',\n",
    "    normalize=True,\n",
    "    model_backbone='llava_qwen2',\n",
    "    # lora=True\n",
    ")\n",
    "data_args = DataArguments()\n",
    "processor = load_processor(model_args, data_args)\n",
    "model = MMEBModel.load(model_args)\n",
    "model = model.to('cuda', dtype=torch.bfloat16)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4ce7e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 15])\n",
      "torch.Size([1, 3, 1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "inputs = processor(text=f'{VLM_IMAGE_TOKENS[LLAVA_QWEN2]} Represent the given image with the following question: What is in the image',\n",
    "                   images=Image.open('assets/example.jpg'),\n",
    "                   return_tensors=\"pt\")\n",
    "inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
    "print(inputs['input_ids'].shape)\n",
    "print(inputs['images'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8160422d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 896])\n"
     ]
    }
   ],
   "source": [
    "with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
    "    image_features = model.encoder.encode_images(inputs['images'])\n",
    "print(image_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf621c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_tower = model.encoder.get_vision_tower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc935d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training': False, '_parameters': {}, '_buffers': {}, '_non_persistent_buffers_set': set(), '_backward_pre_hooks': OrderedDict(), '_backward_hooks': OrderedDict(), '_is_full_backward_hook': None, '_forward_hooks': OrderedDict(), '_forward_hooks_with_kwargs': OrderedDict(), '_forward_hooks_always_called': OrderedDict(), '_forward_pre_hooks': OrderedDict(), '_forward_pre_hooks_with_kwargs': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_state_dict_pre_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_load_state_dict_post_hooks': OrderedDict(), '_modules': {'vision_tower': MCi(\n",
      "  (model): FastViT(\n",
      "    (patch_embed): Sequential(\n",
      "      (0): MobileOneBlock(\n",
      "        (se): Identity()\n",
      "        (activation): GELU(approximate='none')\n",
      "        (reparam_conv): Conv2d(3, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (1): MobileOneBlock(\n",
      "        (se): Identity()\n",
      "        (activation): GELU(approximate='none')\n",
      "        (reparam_conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96)\n",
      "      )\n",
      "      (2): MobileOneBlock(\n",
      "        (se): Identity()\n",
      "        (activation): GELU(approximate='none')\n",
      "        (reparam_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (network): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96, bias=False)\n",
      "              (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96, bias=False)\n",
      "              (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): PatchEmbed(\n",
      "        (proj): Sequential(\n",
      "          (0): ReparamLargeKernelConv(\n",
      "            (activation): GELU(approximate='none')\n",
      "            (se): Identity()\n",
      "            (lkb_reparam): Conv2d(96, 192, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=96)\n",
      "          )\n",
      "          (1): MobileOneBlock(\n",
      "            (se): Identity()\n",
      "            (activation): GELU(approximate='none')\n",
      "            (reparam_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
      "              (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
      "              (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
      "              (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (3): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
      "              (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (4): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
      "              (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (5): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
      "              (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (6): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
      "              (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (7): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
      "              (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (8): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
      "              (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (9): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
      "              (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (10): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
      "              (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (11): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)\n",
      "              (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (3): PatchEmbed(\n",
      "        (proj): Sequential(\n",
      "          (0): ReparamLargeKernelConv(\n",
      "            (activation): GELU(approximate='none')\n",
      "            (se): Identity()\n",
      "            (lkb_reparam): Conv2d(192, 384, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=192)\n",
      "          )\n",
      "          (1): MobileOneBlock(\n",
      "            (se): Identity()\n",
      "            (activation): GELU(approximate='none')\n",
      "            (reparam_conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (3): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (4): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (5): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (6): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (7): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (8): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (9): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (10): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (11): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (12): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (13): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (14): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (15): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (16): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (17): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (18): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (19): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (20): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (21): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (22): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (23): RepMixerBlock(\n",
      "          (token_mixer): RepMixer(\n",
      "            (reparam_conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384, bias=False)\n",
      "              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (5): PatchEmbed(\n",
      "        (proj): Sequential(\n",
      "          (0): ReparamLargeKernelConv(\n",
      "            (activation): GELU(approximate='none')\n",
      "            (se): Identity()\n",
      "            (lkb_reparam): Conv2d(384, 768, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=384)\n",
      "          )\n",
      "          (1): MobileOneBlock(\n",
      "            (se): Identity()\n",
      "            (activation): GELU(approximate='none')\n",
      "            (reparam_conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): RepCPE(\n",
      "        (reparam_conv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "      )\n",
      "      (7): Sequential(\n",
      "        (0): AttentionBlock(\n",
      "          (norm): LayerNormChannel()\n",
      "          (token_mixer): MHSA(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "              (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): AttentionBlock(\n",
      "          (norm): LayerNormChannel()\n",
      "          (token_mixer): MHSA(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "              (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): AttentionBlock(\n",
      "          (norm): LayerNormChannel()\n",
      "          (token_mixer): MHSA(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "              (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (3): AttentionBlock(\n",
      "          (norm): LayerNormChannel()\n",
      "          (token_mixer): MHSA(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768, bias=False)\n",
      "              (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (8): PatchEmbed(\n",
      "        (proj): Sequential(\n",
      "          (0): ReparamLargeKernelConv(\n",
      "            (activation): GELU(approximate='none')\n",
      "            (se): Identity()\n",
      "            (lkb_reparam): Conv2d(768, 1536, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=768)\n",
      "          )\n",
      "          (1): MobileOneBlock(\n",
      "            (se): Identity()\n",
      "            (activation): GELU(approximate='none')\n",
      "            (reparam_conv): Conv2d(1536, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (9): RepCPE(\n",
      "        (reparam_conv): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
      "      )\n",
      "      (10): Sequential(\n",
      "        (0): AttentionBlock(\n",
      "          (norm): LayerNormChannel()\n",
      "          (token_mixer): MHSA(\n",
      "            (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536, bias=False)\n",
      "              (bn): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(1536, 6144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(6144, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): AttentionBlock(\n",
      "          (norm): LayerNormChannel()\n",
      "          (token_mixer): MHSA(\n",
      "            (qkv): Linear(in_features=1536, out_features=4608, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (convffn): ConvFFN(\n",
      "            (conv): Sequential(\n",
      "              (conv): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536, bias=False)\n",
      "              (bn): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (fc1): Conv2d(1536, 6144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Conv2d(6144, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv_exp): MobileOneBlock(\n",
      "      (se): SEBlock(\n",
      "        (reduce): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (expand): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (activation): GELU(approximate='none')\n",
      "      (reparam_conv): Conv2d(1536, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536)\n",
      "    )\n",
      "    (head): GlobalPool2D()\n",
      "  )\n",
      ")}, 'is_loaded': True, 'vision_tower_name': 'mobileclip_l_1024', 'tune_vision_tower': True, 'input_image_size': 1024, 'cfg_only': {'embed_dim': 768, 'image_cfg': {'image_size': 1024, 'model_name': 'fastvithd', 'embed_dim': 3072, 'patch_size': 64}, 'text_cfg': {'context_length': 77, 'vocab_size': 49408, 'dim': 768, 'ffn_multiplier_per_layer': 4.0, 'n_heads_per_layer': 12, 'n_transformer_layers': 12, 'norm_layer': 'layer_norm_fp32', 'causal_masking': False, 'model_name': 'base'}}, 'image_processor': CLIPImageProcessor {\n",
      "  \"crop_size\": {\n",
      "    \"height\": 1024,\n",
      "    \"width\": 1024\n",
      "  },\n",
      "  \"do_center_crop\": true,\n",
      "  \"do_convert_rgb\": true,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0\n",
      "  ],\n",
      "  \"image_processor_type\": \"CLIPImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    1.0,\n",
      "    1.0,\n",
      "    1.0\n",
      "  ],\n",
      "  \"resample\": 3,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"shortest_edge\": 1024\n",
      "  }\n",
      "}\n",
      ", '_is_hf_initialized': True}\n"
     ]
    }
   ],
   "source": [
    "# xem ton b config trong model\n",
    "print(vision_tower.__dict__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5c4969e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vision_tower.cfg_only['image_cfg']['patch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34cb357d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/workspace/VLM2Vec/src/model/baseline_backbone/internvideo2/modeling_internvideo2.py:539: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast(enabled=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DropoutAddRMSNorm of flash_attn is not installed!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-29 03:23:26,277] INFO [src.utils.basic_utils:21] Loading processor from: TIGER-Lab/VLM2Vec-Qwen2VL-7B\n",
      "[2025-11-29 03:23:26,280] DEBUG [urllib3.connectionpool:1051] Starting new HTTPS connection (1): huggingface.co:443\n",
      "[2025-11-29 03:23:26,652] DEBUG [urllib3.connectionpool:546] https://huggingface.co:443 \"HEAD /TIGER-Lab/VLM2Vec-Qwen2VL-7B/resolve/main/preprocessor_config.json HTTP/11\" 307 0\n",
      "[2025-11-29 03:23:26,664] DEBUG [urllib3.connectionpool:546] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/TIGER-Lab/VLM2Vec-Qwen2VL-7B/5aec77d4014be33b00aff8f7856865214682f3d9/preprocessor_config.json HTTP/11\" 200 0\n",
      "[2025-11-29 03:23:26,946] DEBUG [urllib3.connectionpool:546] https://huggingface.co:443 \"HEAD /TIGER-Lab/VLM2Vec-Qwen2VL-7B/resolve/main/tokenizer_config.json HTTP/11\" 307 0\n",
      "[2025-11-29 03:23:26,957] DEBUG [urllib3.connectionpool:546] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/TIGER-Lab/VLM2Vec-Qwen2VL-7B/5aec77d4014be33b00aff8f7856865214682f3d9/tokenizer_config.json HTTP/11\" 200 0\n",
      "[2025-11-29 03:23:27,623] DEBUG [urllib3.connectionpool:546] https://huggingface.co:443 \"HEAD /TIGER-Lab/VLM2Vec-Qwen2VL-7B/resolve/main/preprocessor_config.json HTTP/11\" 307 0\n",
      "[2025-11-29 03:23:27,638] DEBUG [urllib3.connectionpool:546] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/TIGER-Lab/VLM2Vec-Qwen2VL-7B/5aec77d4014be33b00aff8f7856865214682f3d9/preprocessor_config.json HTTP/11\" 200 0\n",
      "[2025-11-29 03:23:27,924] DEBUG [urllib3.connectionpool:546] https://huggingface.co:443 \"HEAD /TIGER-Lab/VLM2Vec-Qwen2VL-7B/resolve/main/tokenizer_config.json HTTP/11\" 307 0\n",
      "[2025-11-29 03:23:27,936] DEBUG [urllib3.connectionpool:546] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/TIGER-Lab/VLM2Vec-Qwen2VL-7B/5aec77d4014be33b00aff8f7856865214682f3d9/tokenizer_config.json HTTP/11\" 200 0\n",
      "[2025-11-29 03:23:29,090] DEBUG [urllib3.connectionpool:546] https://huggingface.co:443 \"HEAD /TIGER-Lab/VLM2Vec-Qwen2VL-7B/resolve/main/processor_config.json HTTP/11\" 404 0\n",
      "[2025-11-29 03:23:29,368] DEBUG [urllib3.connectionpool:546] https://huggingface.co:443 \"HEAD /TIGER-Lab/VLM2Vec-Qwen2VL-7B/resolve/main/chat_template.json HTTP/11\" 307 0\n",
      "[2025-11-29 03:23:29,379] DEBUG [urllib3.connectionpool:546] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/TIGER-Lab/VLM2Vec-Qwen2VL-7B/5aec77d4014be33b00aff8f7856865214682f3d9/chat_template.json HTTP/11\" 200 0\n",
      "[2025-11-29 03:23:29,665] DEBUG [urllib3.connectionpool:546] https://huggingface.co:443 \"HEAD /TIGER-Lab/VLM2Vec-Qwen2VL-7B/resolve/main/chat_template.jinja HTTP/11\" 404 0\n",
      "[2025-11-29 03:23:30,541] DEBUG [urllib3.connectionpool:546] https://huggingface.co:443 \"HEAD /TIGER-Lab/VLM2Vec-Qwen2VL-7B/resolve/main/config.json HTTP/11\" 307 0\n",
      "[2025-11-29 03:23:30,552] DEBUG [urllib3.connectionpool:546] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/TIGER-Lab/VLM2Vec-Qwen2VL-7B/5aec77d4014be33b00aff8f7856865214682f3d9/config.json HTTP/11\" 200 0\n",
      "[2025-11-29 03:23:30,558] INFO [src.utils.basic_utils:21] Loading backbone [qwen2_vl] from TIGER-Lab/VLM2Vec-Qwen2VL-7B\n",
      "[2025-11-29 03:23:30,836] DEBUG [urllib3.connectionpool:546] https://huggingface.co:443 \"HEAD /Qwen/Qwen2-VL-7B-Instruct/resolve/main/config.json HTTP/11\" 307 0\n",
      "[2025-11-29 03:23:30,847] DEBUG [urllib3.connectionpool:546] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/Qwen/Qwen2-VL-7B-Instruct/eed13092ef92e448dd6875b2a00151bd3f7db0ac/config.json HTTP/11\" 200 0\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8fba91fd2b94bf295f6fed3a85099f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-29 03:23:32,278] DEBUG [urllib3.connectionpool:546] https://huggingface.co:443 \"HEAD /Qwen/Qwen2-VL-7B-Instruct/resolve/main/generation_config.json HTTP/11\" 307 0\n",
      "[2025-11-29 03:23:32,289] DEBUG [urllib3.connectionpool:546] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/Qwen/Qwen2-VL-7B-Instruct/eed13092ef92e448dd6875b2a00151bd3f7db0ac/generation_config.json HTTP/11\" 200 0\n",
      "[2025-11-29 03:23:32,293] INFO [src.utils.basic_utils:21] Loading LoRA from TIGER-Lab/VLM2Vec-Qwen2VL-7B\n",
      "[2025-11-29 03:23:32,570] DEBUG [urllib3.connectionpool:546] https://huggingface.co:443 \"HEAD /TIGER-Lab/VLM2Vec-Qwen2VL-7B/resolve/main/adapter_config.json HTTP/11\" 307 0\n",
      "[2025-11-29 03:23:32,580] DEBUG [urllib3.connectionpool:546] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/TIGER-Lab/VLM2Vec-Qwen2VL-7B/5aec77d4014be33b00aff8f7856865214682f3d9/adapter_config.json HTTP/11\" 200 0\n",
      "[2025-11-29 03:24:06,088] DEBUG [urllib3.connectionpool:546] https://huggingface.co:443 \"HEAD /TIGER-Lab/VLM2Vec-Qwen2VL-7B/resolve/main/adapter_model.safetensors HTTP/11\" 404 0\n",
      "[2025-11-29 03:24:06,372] DEBUG [urllib3.connectionpool:546] https://huggingface.co:443 \"HEAD /TIGER-Lab/VLM2Vec-Qwen2VL-7B/resolve/main/adapter_model.bin HTTP/11\" 302 0\n",
      "/opt/conda/lib/python3.11/site-packages/peft/utils/save_and_load.py:328: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  adapters_weights = torch.load(filename, map_location=torch.device(device))\n",
      "[2025-11-29 03:24:06,957] DEBUG [urllib3.connectionpool:546] https://huggingface.co:443 \"HEAD /TIGER-Lab/VLM2Vec-Qwen2VL-7B/resolve/main/adapter_model.safetensors HTTP/11\" 404 0\n",
      "[2025-11-29 03:24:07,239] DEBUG [urllib3.connectionpool:546] https://huggingface.co:443 \"HEAD /TIGER-Lab/VLM2Vec-Qwen2VL-7B/resolve/main/adapter_model.bin HTTP/11\" 302 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MMEBModel(\n",
       "  (encoder): PeftModel(\n",
       "    (base_model): LoraModel(\n",
       "      (model): Qwen2VLForConditionalGeneration(\n",
       "        (visual): Qwen2VisionTransformerPretrainedModel(\n",
       "          (patch_embed): PatchEmbed(\n",
       "            (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)\n",
       "          )\n",
       "          (rotary_pos_emb): VisionRotaryEmbedding()\n",
       "          (blocks): ModuleList(\n",
       "            (0-31): 32 x Qwen2VLVisionBlock(\n",
       "              (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "              (attn): VisionFlashAttention2(\n",
       "                (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "                (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (mlp): VisionMlp(\n",
       "                (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "                (act): QuickGELUActivation()\n",
       "                (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (merger): PatchMerger(\n",
       "            (ln_q): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (0): Linear(in_features=5120, out_features=5120, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Linear(in_features=5120, out_features=3584, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (model): Qwen2VLModel(\n",
       "          (embed_tokens): Embedding(152064, 3584)\n",
       "          (layers): ModuleList(\n",
       "            (0-27): 28 x Qwen2VLDecoderLayer(\n",
       "              (self_attn): Qwen2VLFlashAttention2(\n",
       "                (q_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=3584, out_features=3584, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=3584, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=3584, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ParameterDict(  (default): Parameter containing: [torch.cuda.BFloat16Tensor of size 3584 (cuda:0)])\n",
       "                )\n",
       "                (k_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=3584, out_features=512, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=3584, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ParameterDict(  (default): Parameter containing: [torch.cuda.BFloat16Tensor of size 512 (cuda:0)])\n",
       "                )\n",
       "                (v_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=3584, out_features=512, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=3584, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ParameterDict(  (default): Parameter containing: [torch.cuda.BFloat16Tensor of size 512 (cuda:0)])\n",
       "                )\n",
       "                (o_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=3584, out_features=3584, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=3584, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=3584, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ParameterDict(  (default): Parameter containing: [torch.cuda.BFloat16Tensor of size 3584 (cuda:0)])\n",
       "                )\n",
       "                (rotary_emb): Qwen2VLRotaryEmbedding()\n",
       "              )\n",
       "              (mlp): Qwen2MLP(\n",
       "                (gate_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "                (up_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "                (down_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=18944, out_features=3584, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=18944, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=3584, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ParameterDict(  (default): Parameter containing: [torch.cuda.BFloat16Tensor of size 3584 (cuda:0)])\n",
       "                )\n",
       "                (act_fn): SiLU()\n",
       "              )\n",
       "              (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "              (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "            )\n",
       "          )\n",
       "          (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "          (rotary_emb): Qwen2VLRotaryEmbedding()\n",
       "        )\n",
       "        (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cross_entropy): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.arguments import ModelArguments, DataArguments\n",
    "from src.model.model import MMEBModel\n",
    "from src.model.processor import load_processor, QWEN2_VL, VLM_IMAGE_TOKENS, Qwen2_VL_process_fn\n",
    "from src.utils.basic_utils import batch_to_device\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "model_args = ModelArguments(\n",
    "    model_name='Qwen/Qwen2-VL-7B-Instruct',\n",
    "    checkpoint_path='TIGER-Lab/VLM2Vec-Qwen2VL-7B',\n",
    "    pooling='last',\n",
    "    normalize=True,\n",
    "    model_backbone='qwen2_vl',\n",
    "    lora=True\n",
    ")\n",
    "data_args = DataArguments()\n",
    "\n",
    "processor = load_processor(model_args, data_args)\n",
    "model = MMEBModel.load(model_args)\n",
    "model = model.to('cuda', dtype=torch.bfloat16)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43a5b3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'pixel_values', 'image_grid_thw'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image + Text -> Text\n",
    "inputs = processor(text=f'{VLM_IMAGE_TOKENS[QWEN2_VL]} Represent the given image with the following question: What is in the image',\n",
    "                   images=Image.open('assets/example.jpg'),\n",
    "                   return_tensors=\"pt\")\n",
    "inputs = {key: value.to('cuda') for key, value in inputs.items()}\n",
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6b4566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
